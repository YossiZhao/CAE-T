{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3f1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.types import Device, _size\n",
    "from collections import OrderedDict\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "%matplotlib notebook\n",
    "\n",
    "num_train = 2717\n",
    "num_eval = 276"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa93835",
   "metadata": {},
   "source": [
    "### Read edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8444891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path = '../data/edf/normal/aaaaacby_s004_t000.edf'\n",
    "raw = mne.io.read_raw_edf(file_path)\n",
    "raw.resample(100)    # resampling to xHz\n",
    "sfreq = raw.info['sfreq']   # 100\n",
    "#     logger.info(freq)\n",
    "raw.crop(tmin=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862619cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_frame = raw.to_data_frame(picks=['EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF','EEG F4-REF', \n",
    "                                            'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', \n",
    "                                            'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF',\n",
    "                                            'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', \n",
    "                                            'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee2b0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686f4b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_cp = raw.copy().pick('EEG FP1-REF')\n",
    "raw_cp.crop(tmin=0, tmax=5.0)\n",
    "raw_cp.plot(scalings=dict(eeg=40e-6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8bbf39",
   "metadata": {},
   "source": [
    "### Save to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92dca7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_frame.to_csv('../test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e1270",
   "metadata": {},
   "source": [
    "### Read csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603d408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/seg_csv/aaaaacby_s004_t000_13.csv')\n",
    "df = pd.read_csv('../data/seg_csv/aaaaacby_s004_t000_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04c884",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e01b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a figure and a set of subplots\n",
    "fig, ax = plt.subplots()  # Adjust the grid size as needed\n",
    "ax = ax.plot(df.iloc[1000:1500,1])\n",
    "# ax.set_title(f'Channel {df.iloc[0,1]}')\n",
    "# ax.set_xlabel('Sample Index')\n",
    "# ax.set_ylabel('Signal Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15877385",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "segment = scaler.fit_transform(df.T)\n",
    "segment = segment.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a0360",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()  # Adjust the grid size as needed\n",
    "ax = ax.plot(segment[:,0])\n",
    "# ax.set_title(f'Channel {df.iloc[0,1]}')\n",
    "# ax.set_xlabel('Sample Index')\n",
    "# ax.set_ylabel('Signal Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa533079",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_1 = StandardScaler()\n",
    "segment_1 = scaler_1.fit_transform(df.T)\n",
    "segment_1 = segment.T\n",
    "\n",
    "fig, ax = plt.subplots()  # Adjust the grid size as needed\n",
    "ax = ax.plot(segment[:,0])\n",
    "# ax.set_title(f'Channel {df.iloc[0,1]}')\n",
    "# ax.set_xlabel('Sample Index')\n",
    "# ax.set_ylabel('Signal Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a006db50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a figure and a set of subplots\n",
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(30, 20))  # Adjust the grid size as needed\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each channel in a separate subplot\n",
    "for i in range(19):\n",
    "    ax = axes[i]\n",
    "    ax.plot(df.iloc[:, i])\n",
    "    ax.set_title(f'Channel {i+1}')\n",
    "    ax.set_xlabel('Sample Index')\n",
    "    ax.set_ylabel('Signal Value')\n",
    "\n",
    "# Remove the unused subplot (if the number of subplots is more than the channels)\n",
    "for j in range(19, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust the layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ba4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[500:600, 2]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "939c8ff8",
   "metadata": {},
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "60801f8f",
   "metadata": {},
   "source": [
    "edf_data_path = Path('./data/edf/train/')\n",
    "num_file = 0\n",
    "for file in edf_data_path.glob('**/*.edf'):\n",
    "    num_file += 1\n",
    "    \n",
    "    raw = mne.io.read_raw_edf(file)\n",
    "    \n",
    "    print(len(raw) / raw.info['sfreq']/60)\n",
    "#         freq = raw.info['sfreq']   # 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46bccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e945e6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_len = 6000\n",
    "raw.resample(100)    # resampling to xHz\n",
    "sfreq = raw.info['sfreq']   # 100\n",
    "#     logger.info(freq)\n",
    "raw.crop(tmin=60)    # start from 60 secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8ae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_segments = int(np.floor(raw.times[-1] *sfreq/data_len))\n",
    "pd_frame = raw.to_data_frame(picks=['EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF','EEG F4-REF', \n",
    "                                            'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', \n",
    "                                            'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF',\n",
    "                                            'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', \n",
    "                                            'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_frame.iloc[1,0]\n",
    "segment = pd_frame.iloc[0:6000, 1:]\n",
    "segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b76efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "scaler = Normalizer()\n",
    "seg_nor = scaler.fit_transform(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df78ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seg_nor[1800:2100,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60245936",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec7edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf_data_path = Path('./data/edf/train/')\n",
    "edf_data_path.parts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7ff883",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)  # Use the current module's name\n",
    "logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "test_accuracy = 0.95  # Replace with your actual accuracy calculation\n",
    "logger.info(f\"test accuracy:{test_accuracy}\")  # Log as info"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70b93fce",
   "metadata": {},
   "source": [
    "# classes = {'normal':0, 'abnormal':1}\n",
    "# edf_data_path = Path('./data/edf/train')  # need to modify\n",
    "# label_path = Path('./data/edf/train')\n",
    "# label = pd.DataFrame(columns=['csv_file','label'])\n",
    "\n",
    "# edf_data_path.glob('**/*.edf')\n",
    "for file_path in edf_data_path.glob('**/*.edf'):\n",
    "#     sub_label = str(file_path.parts[3])\n",
    "#     file_name = str(file_path.name).split('.')[0]\n",
    "#     print(sub_label, file_path, file_name)\n",
    "    raw = mne.io.read_raw_edf(file_path)\n",
    "    freq = raw.info['sfreq']   # 250\n",
    "    logger.info(raw.times[-1])\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6c7e2d8",
   "metadata": {},
   "source": [
    "df = pd.read_csv('./data/origin_csv/train/aaaaaaat_s002_t001_172.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2348531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(max_length:int, d_model:int, model_type='sinusoidal'):\n",
    "    \"\"\"\n",
    "    Generates positional encodings for a given maximum sequence length and model dimensionality.\n",
    "\n",
    "    Args:\n",
    "        max_length (int): The maximum length of the sequence.\n",
    "        d_model (int): The dimensionality of the model.\n",
    "        model_type (str): The type of positional encoding to use. Defaults to 'sinusoidal'.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The positional encoding matrix of shape (max_length, d_model).\n",
    "    \"\"\"\n",
    "\n",
    "    if model_type == 'sinusoidal':\n",
    "        pe = np.zeros((max_length, d_model))\n",
    "        position = np.arange(0, max_length, dtype=np.float32).reshape(-1, 1)\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = np.sin(position * div_term)\n",
    "        if pe.size % 2 != 0:\n",
    "            pe[:, 1::2] = np.cos(position[:-1] * div_term)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_type: {}\".format(model_type))\n",
    "\n",
    "    return pe\n",
    "\n",
    "# pe_train = positional_encoding(X_train.shape[0], X_train.shape[1])\n",
    "# pe_test = positional_encoding(X_test.shape[0], X_test.shape[1])\n",
    "# # Add positional encoding to the signal\n",
    "# X_train =  X_train + pe_train # Add corresponding row of pe matrix\n",
    "# X_test =  X_test + pe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe34d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_clip(data_path:Path, result_path:Path, data_len:int): # data_path = Path('./data/edf/train/'); \n",
    "                                                                # result_path = Path('./data/origin_csv/train/')\n",
    "    if os.path.exists(result_dir_path):\n",
    "        shutil.rmtree(result_dir_path)\n",
    "    os.mkdir(result_dir_path)\n",
    "    \n",
    "    \n",
    "    channels = ['Fp1', 'Fp2', 'F3','F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', 'F8', 'T3', 'T4',\n",
    "                'T5', 'T6', 'Fz', 'Cz', 'Pz']\n",
    "    label_path = data_path\n",
    "    stage = str(data_path.parts[-1])\n",
    "    label = pd.DataFrame(columns=['csv_file','label'])\n",
    "#     pe = positional_encoding(data_len, len(channels))    # 1000 needs to adjust according my study\n",
    "    \n",
    "    \n",
    "    for file_path in data_path.glob('**/*.edf'):\n",
    "        sub_label = str(file_path.parts[3])\n",
    "        file_name = str(file_path.name).split('.')[0]\n",
    "    #     print(sub_label, file_path, file_name)\n",
    "        raw = mne.io.read_raw_edf(file_path)\n",
    "        raw.resample(100)    # resampling to xHz\n",
    "        sfreq = raw.info['sfreq']   # 100\n",
    "    #     logger.info(freq)\n",
    "        raw.crop(tmin=60)    # start from 60 secs\n",
    "#         n_segments = int(np.floor(raw.times[-1] *sfreq/data_len))\n",
    "        start, end = 0, data_len   # initilize slide window\n",
    "        count = 0  # initilize num.of segments\n",
    "        \n",
    "        pd_frame = raw.to_data_frame(picks=['EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF','EEG F4-REF', \n",
    "                                            'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', \n",
    "                                            'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF',\n",
    "                                            'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', \n",
    "                                            'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "    #     channels = ['EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF','EEG F4-REF', \n",
    "    #                                         'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', \n",
    "    #                                         'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF',\n",
    "    #                                         'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', \n",
    "    #                                         'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF']    \n",
    "#         print(pd_frame.shape)\n",
    "    #     logger.debug(pe)  # Log as info\n",
    "        while end <= pd_frame.shape[0]:\n",
    "#         for i in range(n_segments):\n",
    "#             start_time = i * data_len  # Start time of the segment in seconds\n",
    "#             end_time = start_time + data_len  # End time of the segment in seconds\n",
    "\n",
    "            # Extract the segment\n",
    "            segment = pd_frame.iloc[start:end, 1:]\n",
    "    #         logger.info(segment.shape, file_name)\n",
    "\n",
    "#             scaler = Normalizer()\n",
    "#             segment = scaler.fit_transform(segment.T)\n",
    "#             segment = segment.T + pe\n",
    "#             np.savetxt(f'{str(result_dir_path)}/{file_name}_{count+1}.csv', segment, header=','.join(channels), \n",
    "#                        delimiter=',')\n",
    "            segment.to_csv(f'{str(result_dir_path)}/{file_name}_{count+1}.csv', index=False)\n",
    "\n",
    "            label.loc[len(label)] = [f'{file_name}_{count+1}.csv', sub_label]\n",
    "            start += data_len\n",
    "            end += data_len\n",
    "            count += 1\n",
    "        \n",
    "        raw.close()\n",
    "    label.to_csv(f'../data/{stage}_label_{segment_length}.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d542a",
   "metadata": {},
   "source": [
    "### Process training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27daf542",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training dataset\n",
    "# edf_data_path = Path('../../Dataset/tuh_eeg_abnormal/v3.0.1/edf/train/')  # need to modify\n",
    "edf_data_path = Path('../data/edf/train/')\n",
    "result_dir_path = Path('../data/seg_csv/train_12000')\n",
    "segment_length = 12000\n",
    "data_clip(edf_data_path, result_dir_path, segment_length)\n",
    "\n",
    "# edf_data_path = Path('../../Dataset/tuh_eeg_abnormal/v3.0.1/edf/eval/')  # need to modify\n",
    "# result_dir_path = Path('./data/seg_csv/eval_12000/')\n",
    "# data_clip(edf_data_path, result_dir_path, segment_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a112d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = Normalizer()\n",
    "segment = scaler.fit_transform(segment.T)\n",
    "#             segment = segment + pe\n",
    "#         if segment.shape[0]>1000\n",
    "segment = pd.DataFrame(segment.T, columns=channels)\n",
    "\n",
    "#         data, times = raw[:, start_time*freq:end_time*freq]\n",
    "#     print(times)\n",
    "#         df = raw.to_data_frame()\n",
    "segment.to_csv(f'{str(result_dir_path)}/{file_name}_{i+1}.csv', index=False)\n",
    "#         np.savetxt(f'./data/origin_csv/train/{file_name}_{i+1}.csv', segment, header=','.join(channels), \n",
    "#                    delimiter=',')\n",
    "label.loc[len(label)] = [f'{file_name}_{i+1}.csv', sub_label]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "368fd2a1",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "raw = mne.io.read_raw_edf('./data/edf/aaaaaaav_s004_t000.edf')\n",
    "freq = raw.info['sfreq']\n",
    "raw.crop(tmin=120)\n",
    "n_segments = int(np.floor(raw.times[-1] / 4))\n",
    "# raw.pick(['eeg']).plot()\n",
    "raw.pick(['EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF','EEG F4-REF', \n",
    "          'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', \n",
    "          'EEG O1-REF', 'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF',\n",
    "          'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF', 'EEG T6-REF', \n",
    "          'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "\n",
    "# label file\n",
    "label = pd.DataFrame(columns=['data','label'])\n",
    "# pd_frame = raw.to_data_frame(picks=['EEG FP1-REF', 'EEG FP2-REF', 'EEG F7-REF','EEG F3-REF', \n",
    "#                                         'EEG FZ-REF', 'EEG F4-REF', 'EEG F8-REF', 'EEG T3-REF', \n",
    "#                                         'EEG C3-REF', 'EEG CZ-REF', 'EEG C3-REF', 'EEG T4-REF',\n",
    "#                                         'EEG P7-REF', 'EEG P3-REF', 'EEG PZ-REF', 'EEG P4-REF', \n",
    "#                                         'EEG P8-REF', 'EEG O1-REF', 'EEG O2-REF'])\n",
    "\n",
    "\n",
    "for i in range(n_segments):\n",
    "    start_time = i * 4  # Start time of the segment in seconds\n",
    "    end_time = start_time + 4  # End time of the segment in seconds\n",
    "\n",
    "    # Extract the segment\n",
    "    data, times = raw[:, start_time*freq:end_time*freq]\n",
    "#     print(times)\n",
    "#     df = raw.to_data_frame()\n",
    "#     pd_frame.to_csv('f./data/csv/segment_{i+1}.csv')\n",
    "    \n",
    "\n",
    "#     # Save the segment as a CSV file\n",
    "    np.savetxt(f'./data/csv/segment_{i+1}.csv', data, delimiter=',')  # Transpose for channel-first format\n",
    "#     label = label.append({'image':f'segment_{i+1}.csv','label':'normal'},ignore_index=True)\n",
    "    label.loc[len(label)] = {'data':f'segment_{i+1}.csv','label':'normal'}\n",
    "#     df.to_csv(f'./data/csv/segment_{i+1}.csv')\n",
    "#     print(data.shape)\n",
    "#     print(data.shape)\n",
    "\n",
    "# Close the raw data file\n",
    "raw.close()\n",
    "# raw_data.info\n",
    "# raw_data.plot()\n",
    "\n",
    "\n",
    "label.to_csv('./data/label.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f02f2",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "conda-env-python38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": "50",
    "lenVar": "80"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
