{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f8369d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:38:13.645682: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-10 10:38:13.664895: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 10:38:13.992354: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import argparse\n",
    "from typing import List, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.types import Device, _size\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import init\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from configs.config import configs\n",
    "\n",
    "from models.resnet1D import *\n",
    "from models.pe import PositionalEncoding\n",
    "from models.transformer_encoder import transformer_classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b320dd3e",
   "metadata": {},
   "source": [
    "### Initilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb628e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current accuracy: %0.95\n",
      "INFO:__main__:Current accuracy: %0.95\n"
     ]
    }
   ],
   "source": [
    "# Init logging\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)  # Use the current module's name\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "acc_example = 0.95  # Replace with your actual accuracy calculation\n",
    "logger.info(f\"Current accuracy: %{acc_example}\")  # Log as info\n",
    "# logger.debug(\"Current accuracy: %.2f\", accuracy)  # Log as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "535cc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"config_file\", metavar=\"FILE\", help=\"config file\")\n",
    "# parser.add_argument('--run-dir', metavar='DIR', help='run directory')\n",
    "# parser.add_argument('--pdb', action='store_true', help='pdb')\n",
    "args = parser.parse_args(args=['configs/abnormal_12000.yml'])\n",
    "# args, opts = parser.parse_known_args()\n",
    "# f = 'configs/eeg_pt.yml'\n",
    "with open(args.config_file, 'r') as file:\n",
    "    Configs = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Configs['checkpoint']['checkpoint_dir'] is not None:\n",
    "    print(Configs['checkpoint']['checkpoint_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6de7e7",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "78c47be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, input_size: int, n_channels: int, model_hyp: dict, classes: int):\n",
    "        super(model, self).__init__()\n",
    "        self.pe = PositionalEncoding(d_model=n_channels, max_len=input_size)\n",
    "        self.ae = resnet18()\n",
    "#         self.transformer_encoder = transformer_classifier(input_size, n_channels, model_hyp, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.pe(x)\n",
    "        z = z.transpose(-1,-2)\n",
    "        z = self.ae(z)\n",
    "#         z = self.transformer_encoder(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9267a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "d_model = 19\n",
    "max_len = 12000\n",
    "x = torch.rand(batch, max_len, d_model)\n",
    "pe = model(input_size=Configs['input_size'],\n",
    "           n_channels = Configs['n_channels'],\n",
    "           model_hyp=Configs['model'],\n",
    "           classes=len(Configs['dataset']['classes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e7d756d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:models.resnet1D:data shape is: torch.Size([16, 19, 12000])\n",
      "DEBUG:models.resnet1D:data shape after conv1: torch.Size([16, 152, 6000])\n",
      "DEBUG:models.resnet1D:data shape after bn1: torch.Size([16, 152, 6000])\n",
      "DEBUG:models.resnet1D:data shape after maxpool: torch.Size([16, 152, 3000])\n",
      "DEBUG:models.resnet1D:layer1\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([16, 152, 3000])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([16, 152, 3000])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([16, 152, 3000])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([16, 152, 3000])\n",
      "DEBUG:models.resnet1D:layer2\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([16, 304, 1500])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([16, 304, 1500])\n",
      "DEBUG:models.resnet1D:data shape after downsample: torch.Size([16, 304, 1500])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([16, 304, 1500])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([16, 304, 1500])\n",
      "DEBUG:models.resnet1D:layer3\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([16, 608, 750])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([16, 608, 750])\n",
      "DEBUG:models.resnet1D:data shape after downsample: torch.Size([16, 608, 750])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([16, 608, 750])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([16, 608, 750])\n",
      "DEBUG:models.resnet1D:layer4\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([16, 1216, 375])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([16, 1216, 375])\n",
      "DEBUG:models.resnet1D:data shape after downsample: torch.Size([16, 1216, 375])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([16, 1216, 375])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([16, 1216, 375])\n",
      "DEBUG:models.resnet1D:data shape after avgpool: torch.Size([16, 19, 256])\n",
      "DEBUG:models.resnet1D:data shape after flatten: torch.Size([16, 4864])\n"
     ]
    }
   ],
   "source": [
    "out = pe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0387e8ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1000])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e7804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = Configs['dataset']['train_data_dir']\n",
    "train_label_dir = Configs['dataset']['train_label_dir']\n",
    "\n",
    "val_data_dir = Configs['dataset']['val_data_dir']\n",
    "val_label_dir = Configs['dataset']['val_label_dir']\n",
    "\n",
    "label_dict = Configs['dataset']['classes']\n",
    "train_dataset = customDataset(data_dir=train_data_dir,\n",
    "                              label_dir=train_label_dir,\n",
    "                              label_dict=label_dict)\n",
    "val_dataset = customDataset(data_dir=val_data_dir,\n",
    "                            label_dir=val_label_dir,\n",
    "                            label_dict=label_dict)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=Configs['train']['batch_size'],\n",
    "                              shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "eval_loader = DataLoader(dataset=val_dataset, num_workers=16, shuffle=True, pin_memory=True)\n",
    "\n",
    "# classifier = model(input_size=Configs['input_size'],\n",
    "#                                     n_channels = Configs['n_channels'],\n",
    "#                                     model_hyp=Configs['model'],\n",
    "#                                     classes=len(Configs['dataset']['classes'])).to('cuda')\n",
    "\n",
    "classifier = resnet18(groups=Configs['n_channels'], num_classes=len(Configs['dataset']['classes'])).to('cuda')\n",
    "optimizer = torch.optim.Adam(classifier.parameters(),betas=(0.9,0.999),lr=Configs['optimizer']['init_lr'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(Configs['tensorboard']['runs_dir']+'train_board')    # Initilize tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6803bab0",
   "metadata": {},
   "source": [
    "#### Check eval results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5baeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_para = torch.load('weights/resnet18_best.pth')\n",
    "classifier.load_state_dict(model_para['model_state_dict'])\n",
    "classifier.cuda().eval()\n",
    "\n",
    "train_signal = iter(train_loader)\n",
    "eval_signal = iter(eval_loader)\n",
    "\n",
    "train_data = next(train_signal)\n",
    "\n",
    "x_train, y_train = train_data[0].to('cuda'), train_data[1].to('cuda')\n",
    "train_pred = classifier(x_train)\n",
    "train_loss = criterion(train_pred, y_train)\n",
    "train_loss\n",
    "\n",
    "eval_data = next(eval_signal)\n",
    "\n",
    "x_eval, y_eval = eval_data[0].to('cuda'), eval_data[1].to('cuda')\n",
    "eval_pred = classifier(x_eval)\n",
    "eval_loss = criterion(eval_pred, y_eval)\n",
    "eval_loss\n",
    "\n",
    "train_pred, eval_pred\n",
    "y_train, y_eval\n",
    "\n",
    "_, predicted = torch.max(eval_pred, 1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600abd7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Validate results\n",
    "\n",
    "import torch.nn.functional as F\n",
    "val_loss = 0\n",
    "total = 0\n",
    "correct = 0\n",
    "for batch_index, (data,target,_) in enumerate(eval_loader, 0):\n",
    "    data, target = data.to('cuda'), target.to('cuda')\n",
    "    outputs = classifier(data)\n",
    "    print(_)\n",
    "    loss = criterion(outputs, target)\n",
    "    val_loss += loss.item()\n",
    "    probabilities = F.softmax(outputs, dim=1)\n",
    "    print(loss.item(), probabilities)\n",
    "    _, predicted = torch.max(probabilities, 1)\n",
    "    print(predicted, target)\n",
    "    total += target.size(0)  # Total number of samples\n",
    "    correct += (predicted == target).sum().item()  # Count correct predictions\n",
    "    print(correct, total)\n",
    "    val_loss /= len(eval_loader)\n",
    "    val_accuracy = 100 * correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39bd691",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e13daac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, data_dir:str, label_dir:str, label_dict:dict, transform=None):\n",
    "#         self.annotations = pd.read_csv(label_dir)\n",
    "        self.data_dir = data_dir   # './data/origin_csv/train'\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.files = os.listdir(self.data_dir)\n",
    "        self.annotations = pd.read_csv(self.label_dir)\n",
    "        self.label_dict = label_dict\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_path = os.path.join(self.data_dir, self.files[index])\n",
    "        data = pd.read_csv(data_path)\n",
    "        data = torch.tensor(data.values, dtype=torch.float32)\n",
    "        file_name = self.files[index]\n",
    "        \n",
    "        label = torch.tensor(int(self.label_dict[self.annotations.iloc[index,1]]))\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "            \n",
    "        return (data, label, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d0d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# label_dic = {'normal':0, 'abnormal':1}\n",
    "\n",
    "    \n",
    "# transform = transforms.Compose([\n",
    "#     transforms.MinMaxScaler(feature_range=(0, 1)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "# combined_dataset = ConcatDataset([train_dataset, eval_dataset])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a157aec",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e93cba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Learning rate update policy\n",
    "def poly_lr_scheduler(optimizer, init_lr, iter, lr_decay_iter=1,\n",
    "                      max_iter=0, power=0.9):\n",
    "    \"\"\"Polynomial decay of learning rate\n",
    "        :param init_lr is base learning rate\n",
    "        :param iter is a current iteration\n",
    "        :param lr_decay_iter how frequently decay occurs, default is 1\n",
    "        :param max_iter is number of maximum iterations\n",
    "        :param power is a polymomial power\n",
    "    \"\"\"\n",
    "    if max_iter == 0:\n",
    "        raise Exception(\"MAX ITERATION CANNOT BE ZERO!\")\n",
    "    if iter % lr_decay_iter or iter > max_iter:\n",
    "        return optimizer\n",
    "    lr = init_lr * (1 - iter / max_iter) ** power\n",
    "    logger.info(f'lr=: {lr}')\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c11398",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Configs:dict):\n",
    "    train_data_dir = Configs['dataset']['train_data_dir']\n",
    "    train_label_dir = Configs['dataset']['train_label_dir']\n",
    "\n",
    "    val_data_dir = Configs['dataset']['val_data_dir']\n",
    "    val_label_dir = Configs['dataset']['val_label_dir']\n",
    "\n",
    "    label_dict = Configs['dataset']['classes']\n",
    "    train_dataset = customDataset(data_dir=train_data_dir,\n",
    "                                  label_dir=train_label_dir,\n",
    "                                  label_dict=label_dict)\n",
    "    val_dataset = customDataset(data_dir=val_data_dir,\n",
    "                                label_dir=val_label_dir,\n",
    "                                label_dict=label_dict)\n",
    "    \n",
    "    train_loader = DataLoader(dataset=train_dataset, batch_size=Configs['train']['batch_size'],\n",
    "                                  shuffle=True, num_workers=16, pin_memory=True)\n",
    "\n",
    "    eval_loader = DataLoader(dataset=val_dataset, num_workers=16, shuffle=True, pin_memory=True)\n",
    "\n",
    "    classifier = transformer_classifier(input_size=Configs['input_size'], \n",
    "                                        n_channels = Configs['n_channels'],\n",
    "                                        model_hyp=Configs['model'],\n",
    "                                        classes=len(Configs['dataset']['classes'])).to('cuda')\n",
    "    optimizer = torch.optim.Adam(classifier.parameters(),betas=(0.9,0.9),lr=Configs['optimizer']['init_lr'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    writer = SummaryWriter(Configs['tensorboard']['runs_dir']+'train_board')    # Initilize tensorflow\n",
    "    \n",
    "    ### Warmup training\n",
    "    warmup_steps = Configs['train']['warmup_steps']\n",
    "    warmup_step = 0\n",
    "    min_loss = 1\n",
    "    while warmup_step < warmup_steps:\n",
    "        for batch_index, (data,target,_) in enumerate(train_loader, 0):\n",
    "            if warmup_step < warmup_steps:\n",
    "        #     for batch_index, data in enumerate(train_loader, 0):\n",
    "                data, target = data.to('cuda'), target.to('cuda')\n",
    "                y = classifier(data)\n",
    "        #         logger.debug(f\"y size:{y.shape}, tatget size{target.shape}\")\n",
    "                warmup_loss = criterion(y, target)\n",
    "                optimizer.zero_grad()\n",
    "                warmup_loss.backward()\n",
    "                optimizer.step()\n",
    "        #         logger.info(f'Epoch: {epoch+1}, Train Loss: {train_loss}')\n",
    "                logger.info(f\"Warmup Step: {warmup_step}, Warmup Loss: {warmup_loss}\")\n",
    "                writer.add_scalar('Warmup Loss', warmup_loss, global_step=warmup_step)\n",
    "                warmup_step += 1\n",
    "        \n",
    "#         if warmup_step%5==0:\n",
    "#             torch.save(classifier.state_dict(), \n",
    "#                        Configs['checkpoint']['checkpoint_dir']+'inte_transformer_params_last.pth')\n",
    "        if warmup_loss < min_loss:\n",
    "            torch.save(classifier.state_dict(),\n",
    "                       Configs['checkpoint']['checkpoint_dir']+'inte_transformer_params_best.pth')\n",
    "            min_loss = warmup_loss\n",
    "        \n",
    "    \n",
    "    ### train\n",
    "#     step = 0\n",
    "#     epochs = Configs['train']['n_epochs']\n",
    "#     for epoch in range(epochs):\n",
    "#         # Training loop\n",
    "#         poly_lr_scheduler(optimizer, init_lr=Configs['optimizer']['init_lr'], iter=epoch, max_iter=epochs)\n",
    "#         for batch_index, (data,target,_) in enumerate(train_loader, 0):\n",
    "#             data, target = data.to('cuda'), target.to('cuda')\n",
    "#             y = classifier(data)\n",
    "#     #         logger.debug(f\"y size:{y.shape}, tatget size{target.shape}\")\n",
    "#             train_loss = criterion(y, target)\n",
    "#             optimizer.zero_grad()\n",
    "#             train_loss.backward()\n",
    "#             optimizer.step()\n",
    "#     #         logger.info(f'Epoch: {epoch+1}, Train Loss: {train_loss}')\n",
    "#             logger.info(f\"Step: {step}, training Loss: {train_loss}\")\n",
    "#             writer.add_scalar('Training Loss', train_loss, global_step=step)\n",
    "#             step += 1\n",
    "        \n",
    "#         if epoch%5==0:\n",
    "#             val_loss = 0\n",
    "#             correct = 0\n",
    "#             total = 0\n",
    "#             accuracy = 0\n",
    "#             with torch.no_grad():\n",
    "#                 for batch_index, (data,target,_) in enumerate(eval_loader, 0):\n",
    "#                     data, target = data.to('cuda'), target.to('cuda')\n",
    "#                     outputs = classifier(data)\n",
    "#                     loss = criterion(outputs, target)\n",
    "#                     val_loss += loss.item()\n",
    "#                     _, predicted = torch.max(outputs, 1)\n",
    "#                     total += target.size(0)  # Total number of samples\n",
    "#                     correct += (predicted == target).sum().item()  # Count correct predictions\n",
    "\n",
    "#             val_loss /= len(eval_loader)\n",
    "#             accuracy = 100 * correct / total\n",
    "#             writer.add_scalar('Validation Loss', val_loss, global_step=step)\n",
    "#             writer.add_scalar('Validation Accuracy', accuracy, global_step=step)\n",
    "#             logger.info(f'Epoch: {epoch}, Train Loss: {train_loss}, Val Loss: {val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "#         torch.save(classifier.state_dict(), \n",
    "#                    Configs['checkpoint']['checkpoint_dir']+'inte_transformer_params_latest.pth')\n",
    "#         if train_loss < min_loss:\n",
    "#             torch.save(classifier.state_dict(),\n",
    "#                        Configs['checkpoint']['checkpoint_dir']+'inte_transformer_params_best.pth')\n",
    "#             min_loss = train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4333cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"config_file\", metavar=\"FILE\", help=\"config file\")\n",
    "# parser.add_argument('--run-dir', metavar='DIR', help='run directory')\n",
    "# parser.add_argument('--pdb', action='store_true', help='pdb')\n",
    "args = parser.parse_args(args=['configs/eeg_torch.yml'])\n",
    "# args, opts = parser.parse_known_args()\n",
    "# f = 'configs/eeg_pt.yml'\n",
    "with open(args.config_file, 'r') as file:\n",
    "    configs = yaml.safe_load(file)\n",
    "    \n",
    "# configs['optimizer']['init_lr']\n",
    "# train(Configs=configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a30a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channels = 19\n",
    "ae_1 = nn.Sequential(nn.Conv1d(in_channels=n_channels, out_channels=n_channels, \n",
    "                               stride=3, kernel_size=7, dilation=1, groups=n_channels,\n",
    "                               padding_mode='reflect'),\n",
    "                     nn.BatchNorm1d(n_channels),\n",
    "                     nn.ReLU())\n",
    "ae_2 = nn.Sequential(nn.Conv1d(in_channels=n_channels, out_channels=n_channels, \n",
    "                               stride=2, kernel_size=4, dilation=1, groups=n_channels,\n",
    "                               padding_mode='reflect'),\n",
    "                     nn.BatchNorm1d(n_channels),\n",
    "                     nn.ReLU())\n",
    "ae_3 = nn.Sequential(nn.Conv1d(in_channels=n_channels, out_channels=n_channels, \n",
    "                               stride=2, kernel_size=4, dilation=1, groups=n_channels,\n",
    "                               padding_mode='reflect'),\n",
    "                     nn.BatchNorm1d(n_channels),\n",
    "                     nn.ReLU())\n",
    "\n",
    "# max_pool = nn.MaxPool1d(kernel_size=2, stride=1)\n",
    "in_data = torch.randn(20, 19, 6000)\n",
    "out_1 = ae_1(in_data)\n",
    "out_2 = ae_2(out_1)\n",
    "out_3 = ae_3(out_2)\n",
    "# out_data = max_pool(out_data)\n",
    "out_1.shape, out_2.shape, out_3.shape\n",
    "# 5660 stride 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40261902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer_classifier(nn.Module):\n",
    "    def __init__(self, input_size:int, n_channels:int, model_hyp:dict, classes:int):\n",
    "        super(transformer_classifier, self).__init__()\n",
    "        \n",
    "        self.ae_1 = nn.Sequential(nn.Conv1d(in_channels=n_channels, out_channels=n_channels, \n",
    "                                     stride=3, kernel_size=7, dilation=1, groups=n_channels,\n",
    "                                            padding_mode='reflect'),\n",
    "                                 nn.BatchNorm1d(n_channels),\n",
    "                                 nn.ReLU())\n",
    "        \n",
    "        self.ae_2 = nn.Sequential(nn.Conv1d(in_channels=n_channels, out_channels=n_channels, \n",
    "                                     stride=2, kernel_size=4, dilation=1, groups=n_channels,\n",
    "                                            padding_mode='reflect'),\n",
    "                                 nn.BatchNorm1d(n_channels),\n",
    "                                 nn.ReLU())\n",
    "\n",
    "        self.ae_3 = nn.Sequential(nn.Conv1d(in_channels=n_channels, out_channels=n_channels, \n",
    "                                     stride=2, kernel_size=4, dilation=1, groups=n_channels,\n",
    "                                            padding_mode='reflect'),\n",
    "                                 nn.BatchNorm1d(n_channels),\n",
    "                                 nn.ReLU())\n",
    "#         self.hidden_size = 597    # need to be calculated every time if you change shape of input\n",
    "#         self.ae = AutoEncoder(input_size=input_size, hidden_size=model_hyp['d_model'])  \n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=model_hyp['d_model'],\n",
    "                                                        nhead=model_hyp['n_head'])\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=model_hyp['n_layer'])\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear = nn.Linear(model_hyp['d_model']*n_channels, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.ae_1(x)\n",
    "        z = self.ae_2(z)\n",
    "        z = self.ae_3(z)\n",
    "#         z = z[:, :, :1496] \n",
    "        logger.debug(f\"ae output size: %{z.shape}\")\n",
    "        z = self.transformer_encoder(z)\n",
    "        logger.debug(f\"transformer output size: %{z.shape}\")\n",
    "        z = self.flatten(z)\n",
    "        logger.debug(f\"flatten output size: %{z.shape}\")\n",
    "        y = self.linear(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8046f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = torch.randn(20, 19, 6000).to('cuda')\n",
    "classifier = transformer_classifier(input_size=6000, n_channels =19,model_hyp=configs['model'],classes=len(configs['dataset']['classes'])).to('cuda')\n",
    "out = classifier(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592583d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target output size of 5\n",
    "m = nn.AdaptiveAvgPool2d((19,5))\n",
    "input = torch.randn(1, 64, 8)\n",
    "output = m(input)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, input_size: int, n_channels: int, model_hyp: dict, classes: int):\n",
    "        super(model, self).__init__()\n",
    "        self.ae = resnet18()\n",
    "        self.transformer_encoder = transformer_classifier(input_size, n_channels, model_hyp, classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.ae(x)\n",
    "        z = self.transformer_encoder(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4b8e1d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:models.resnet1D:data shape is: torch.Size([20, 19, 6000])\n",
      "DEBUG:models.resnet1D:data shape after conv1: torch.Size([20, 152, 3000])\n",
      "DEBUG:models.resnet1D:data shape after bn1: torch.Size([20, 152, 3000])\n",
      "DEBUG:models.resnet1D:data shape after maxpool: torch.Size([20, 152, 1500])\n",
      "DEBUG:models.resnet1D:layer1\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([20, 152, 1500])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([20, 152, 1500])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([20, 152, 1500])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([20, 152, 1500])\n",
      "DEBUG:models.resnet1D:layer2\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([20, 304, 750])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([20, 304, 750])\n",
      "DEBUG:models.resnet1D:data shape after downsample: torch.Size([20, 304, 750])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([20, 304, 750])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([20, 304, 750])\n",
      "DEBUG:models.resnet1D:layer3\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([20, 608, 375])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([20, 608, 375])\n",
      "DEBUG:models.resnet1D:data shape after downsample: torch.Size([20, 608, 375])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([20, 608, 375])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([20, 608, 375])\n",
      "DEBUG:models.resnet1D:layer4\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([20, 1216, 188])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([20, 1216, 188])\n",
      "DEBUG:models.resnet1D:data shape after downsample: torch.Size([20, 1216, 188])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv1-3x3: torch.Size([20, 1216, 188])\n",
      "DEBUG:models.resnet1D:data shape after sub-conv2-3x3: torch.Size([20, 1216, 188])\n",
      "DEBUG:models.resnet1D:data shape after avgpool: torch.Size([20, 19, 256])\n",
      "DEBUG:models.resnet1D:data shape after flatten: torch.Size([20, 4864])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    logger = logging.getLogger(__name__)  # Use the current module's name\n",
    "#     logging.basicConfig(filename=f'./logs/{datetime.now().strftime(\"%y%m%d%H%M\")}_resnet18.log',level=logging.DEBUG)\n",
    "    logging.basicConfig(level=logging.DEBUG)\n",
    "    # logger.setLevel(logging.DEBUG)\n",
    "    handler = logging.StreamHandler()\n",
    "    # formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "    # handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "    resnet18 = resnet18(groups=Configs['n_channels'], num_classes=len(Configs['dataset']['classes']), \n",
    "                        d_model=Configs['model']['d_model'])\n",
    "    in_data = torch.randn(20, 19, 6000)\n",
    "    out = resnet18(in_data)\n",
    "    out.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "conda-env-python38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": "50",
    "lenVar": "80"
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
