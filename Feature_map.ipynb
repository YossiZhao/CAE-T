{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4bac17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 08:41:17.677932: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-15 08:41:17.905860: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-15 08:41:18.442455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import argparse\n",
    "from typing import List, Union\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torch.types import Device, _size\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.nn import init\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import ConcatDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from configs.config import configs\n",
    "\n",
    "from models.pe import PositionalEncoding\n",
    "from models.resnet1D import *\n",
    "from models.transformer_encoder import transformer_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c08df3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current accuracy: %0.95\n",
      "INFO:__main__:Current accuracy: %0.95\n"
     ]
    }
   ],
   "source": [
    "# Init logging\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)  # Use the current module's name\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "# logger.setLevel(logging.DEBUG)\n",
    "handler = logging.StreamHandler()\n",
    "# formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "# handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "acc_example = 0.95  # Replace with your actual accuracy calculation\n",
    "logger.info(f\"Current accuracy: %{acc_example}\")  # Log as info\n",
    "# logger.debug(\"Current accuracy: %.2f\", accuracy)  # Log as info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca8e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"config_file\", metavar=\"FILE\", help=\"config file\")\n",
    "# parser.add_argument('--run-dir', metavar='DIR', help='run directory')\n",
    "# parser.add_argument('--pdb', action='store_true', help='pdb')\n",
    "args = parser.parse_args(args=['configs/abnormal_12000.yml'])\n",
    "# args, opts = parser.parse_known_args()\n",
    "# f = 'configs/eeg_pt.yml'\n",
    "with open(args.config_file, 'r') as file:\n",
    "    Configs = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "190d9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EEGClassifier model\n",
    "class model(nn.Module):\n",
    "    def __init__(self, input_size: int, n_channels: int, model_hyp: dict, classes: int):\n",
    "        super(model, self).__init__()\n",
    "        self.ae = resnet18(n_channels=n_channels, groups=n_channels, num_classes=classes, d_model=model_hyp['d_model'])\n",
    "        self.transformer_encoder = transformer_classifier(input_size, n_channels, model_hyp, classes)\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        r\"\"\"Initiate parameters in the model.\"\"\"\n",
    "        \n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "#                 logger.debug(p.shape)\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                    \n",
    "        for m in self.modules():\n",
    "#             print(m)\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        \n",
    "            elif isinstance(m, nn.LayerNorm):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        print('Complete initiate parameters')\n",
    "\n",
    "    def forward(self, x):\n",
    "#         z = self.pe(x)\n",
    "        z = x.transpose(-1,-2)\n",
    "        z = self.ae(z)\n",
    "        z = self.transformer_encoder(z)\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab70591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform signal\n",
    "def transform(data:Tensor, mean:Tensor, std:Tensor):\n",
    "    normalized_data = (data - mean) / std\n",
    "    return normalized_data\n",
    "\n",
    "# ### Dataset\n",
    "\n",
    "class customDataset(Dataset):\n",
    "    def __init__(self, data_dir:str, label_dir:str, label_dict:dict, mean: list, std: list, transform=None):\n",
    "#         self.annotations = pd.read_csv(label_dir)\n",
    "        self.data_dir = data_dir   # './data/origin_csv/train'\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.files = os.listdir(self.data_dir)\n",
    "        self.annotations = pd.read_csv(self.label_dir)\n",
    "        self.label_dict = label_dict\n",
    "        self.mean = torch.tensor(mean)\n",
    "        self.std = torch.tensor(std)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_path = os.path.join(self.data_dir, self.files[index])\n",
    "        data = pd.read_csv(data_path)\n",
    "        data = torch.tensor(data.values, dtype=torch.float32)\n",
    "        file_name = self.files[index]\n",
    "        \n",
    "        label = torch.tensor(int(self.label_dict[self.annotations.iloc[index,1]]))\n",
    "        \n",
    "        if self.transform:\n",
    "            data = self.transform(data, self.mean, self.std)\n",
    "            \n",
    "        return (data, label, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037da1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete initiate parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yossi/.local/lib/python3.8/site-packages/transformers/utils/generic.py:482: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "train_data_dir = Configs['dataset']['train_data_dir']\n",
    "train_label_dir = Configs['dataset']['train_label_dir']\n",
    "\n",
    "val_data_dir = Configs['dataset']['val_data_dir']\n",
    "val_label_dir = Configs['dataset']['val_label_dir']\n",
    "\n",
    "label_dict = Configs['dataset']['classes']\n",
    "\n",
    "mean =  Configs['dataset']['mean']\n",
    "std =  Configs['dataset']['std']\n",
    "\n",
    "train_dataset = customDataset(data_dir=train_data_dir,\n",
    "                              label_dir=train_label_dir,\n",
    "                              label_dict=label_dict,\n",
    "                              mean=mean,\n",
    "                              std=std,\n",
    "                             transform=transform)\n",
    "val_dataset = customDataset(data_dir=val_data_dir,\n",
    "                            label_dir=val_label_dir,\n",
    "                            label_dict=label_dict,\n",
    "                            mean=mean,\n",
    "                            std=std,\n",
    "                           transform=transform)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=1,\n",
    "                              shuffle=Configs['dataset']['shuffle'], \n",
    "                          num_workers=Configs['dataset']['num_workers'], pin_memory=True)\n",
    "\n",
    "eval_loader = DataLoader(dataset=val_dataset, num_workers=Configs['dataset']['num_workers'], \n",
    "                         shuffle=Configs['dataset']['shuffle'], pin_memory=True)\n",
    "\n",
    "# classifier = model(input_size=Configs['input_size'],\n",
    "#                                     n_channels = Configs['n_channels'],\n",
    "#                                     model_hyp=Configs['model'],\n",
    "#                                     classes=len(Configs['dataset']['classes'])).to('cuda')\n",
    "\n",
    "input_layer = nn.Sequential(\n",
    "#         nn.Embedding(num_embeddings=10000, embedding_dim=512),\n",
    "#         PositionalEncoding(d_model=512, dropout=0.1, max_len=5000)\n",
    "    PositionalEncoding(d_model=Configs['n_channels'], max_len=Configs['input_size'])\n",
    ").to('cuda')\n",
    "\n",
    "classifier = model(input_size=Configs['input_size'],\n",
    "                                        n_channels = Configs['n_channels'],\n",
    "                                        model_hyp=Configs['model'],\n",
    "                                        classes=len(Configs['dataset']['classes'])).to('cuda')\n",
    "optimizer = torch.optim.Adam(classifier.parameters(),betas=(0.9,0.999),lr=Configs['optimizer']['init_lr'])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "writer = SummaryWriter(Configs['tensorboard']['runs_dir']+'train_board')    # Initilize tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d282447",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_train = iter(train_loader)\n",
    "iter_eval = iter(eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c05ead",
   "metadata": {},
   "source": [
    "### Forward hoop define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a folder to save feature maps\n",
    "output_folder = 'feature_maps'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Hook function to save feature maps\n",
    "feature_maps = []\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    feature_maps.append(output)\n",
    "\n",
    "# Function to save feature maps as images\n",
    "def save_feature_maps_as_images(feature_maps, epoch, output_folder):\n",
    "    for idx, fmap in enumerate(feature_maps):\n",
    "        fmap = fmap.detach().cpu().numpy()  # Convert to numpy array\n",
    "        num_channels = fmap.shape[1]\n",
    "        for channel in range(num_channels):\n",
    "            plt.imshow(fmap[0, channel], cmap='viridis')  # Display one feature map channel\n",
    "            plt.colorbar()\n",
    "            plt.title(f'Epoch {epoch}, Feature Map {idx + 1}, Channel {channel + 1}')\n",
    "            plt.savefig(os.path.join(output_folder, f'epoch_{epoch}_feature_map_{idx+1}_channel_{channel+1}.png'))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b3e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target, train_file = next(iter_train)\n",
    "train_data, train_target = train_data.to('cuda'), train_target.to('cuda')\n",
    "\n",
    "eval_data, eval_target, eval_file = next(iter_eval)\n",
    "eval_data, eval_target = eval_data.to('cuda'), eval_target.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model and save feature map as images.\n",
    "# Training loop with feature map extraction every 5 epochs\n",
    "feature_maps = []  # Reset feature maps for the new epoch\n",
    "\n",
    "# Simulate input EEG signal (batch_size=1, channels=1, height=64, width=64)\n",
    "# input_signal = torch.randn(1, 1, 64, 64)\n",
    "\n",
    "# Register the hooks for the desired layers\n",
    "hook1 = model.conv1.register_forward_hook(hook_fn)\n",
    "hook2 = model.conv2.register_forward_hook(hook_fn)\n",
    "\n",
    "# Forward pass\n",
    "input_signal = input_layer(train_data)\n",
    "output = model(input_signal)\n",
    "loss = criterion(output, train_target)  # Simulating target class\n",
    "# optimizer.zero_grad()\n",
    "# loss.backward()\n",
    "# optimizer.step()\n",
    "\n",
    "# Save the feature maps as images\n",
    "save_feature_maps_as_images(feature_maps, epoch + 1, output_folder)\n",
    "\n",
    "# Remove hooks after use to avoid unnecessary overhead\n",
    "hook1.remove()\n",
    "hook2.remove()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "conda-env-python38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
